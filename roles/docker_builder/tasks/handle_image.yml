---

##
## the first part of docker build process runs in the context 
## of the docker build slave host / ansible controller
##

  - set_fact:
      _cur_dockimg: "{{ _dbimg_iter.value }}"
      _dbuild_meta: {}


  - name: determine build container name
    set_fact:
      _bcon_name: "{{ _cur_dockimg.shortname }}-builder"

  - set_fact:
      _build_img_tmpname: "{{ _bcon_name }}-tmpimg"


  - name: remove potential old build container for  ==>>  {{ _dbimg_iter.value.fullname }}
    community.docker.docker_container:
      name: "{{ _bcon_name }}"
      state: absent
    when: not (docker_build_keep_buildcon | default(False))


  - name: initialize build container for  ==>>  {{ _dbimg_iter.value.fullname }}
    community.docker.docker_container:
      name: "{{ _bcon_name }}"
      image: "{{ _cur_dockimg.parent }}"
      state: started

      ## always make sure we have the latest version of parent image
      pull: true

      ##
      ## note: this seems to be needed to avoid that the container 
      ##   closes immediately
      ##
      tty: true

      ##
      ## note: as we literally can get anything as parent, there is 
      ##   a chance that entrypoint is set to something custom, 
      ##   make sure we get a shell there
      ##
      entrypoint: '/bin/sh'

      ##
      ## note: we need a blocking noop command here to keep the 
      ##   container running (we will exec in it later for the 
      ##   actual build stuff), this is the recommended way to 
      ##   do this atm
      ##
      command: -c tail -f /dev/null


  - name: make build container avaible as ansible host  ==>>  {{ _dbimg_iter.value.fullname }}
    add_host:
      name: "{{ _bcon_name }}"
      ansible_connection: docker
      ansible_ssh_user: root


##
## from here we switch into docker container for doing the actual build steps
##

  - name: container build steps
    block:

    ##
    ## note: as we handle docker images / container as standard ansible remote hosts, we need to have python installed there, this means that any image build by this setup will contain a python installation as we will keep it installed because it is not unlikely that the user might want to install python herself as part of her plan for the image and it would be very hard to decide if python was only installed because of ansible or because it really was requested by image setup
    ## if for a specific image the builder really, really dont want python in it we will provide a custom flag to set to force removing python again when building is through
    ##

      - name: bootstrap container system for ansible usage
        include_tasks: bootstrapping/main.yml

        ##
        ## note: standard facts gathering does not work because 
        ##   python is needed for it, luckily it can be called 
        ##   later explicitly like a normal module
        ##
        ## update: how delegations effects (ansible) facts is not 
        ##   that easy to understand, here some observations made by 
        ##   testing:
        ##
        ##                             with delegate_facts   ||   without delegate_facts
        ##
        ##     ansible_facts              docker host                  docker host
        ##     ansible_os_family          docker host                  container
        ##     inventory_hostname         docker host                  docker host
        ##     ansible_env                docker host??                container
        ##     ansible_host               container                    container
        ##     package module             container                    container
        ##
        ##
        ##   further observations:  
        ##
        ##     -> when delegate_facts is set at block level, package 
        ##        module starts to thing being @docker host for some 
        ##        reason than
        ##
        ##
        ##   implication:
        ##
        ##     dont use delegate_facts but simply rerun setup after 
        ##     container section was handled to reset facts to docker 
        ##     host properly, in this scenario things like 
        ##     ansible_os_family and the package module behave correctly 
        ##     inside the container, but we still might get 
        ##     errors / strange bugs because ansible_facts itself is 
        ##     never set to container mode
        ##
      - name: gather facts for  ==>>  {{ _dbimg_iter.value.fullname }}
        block:

            ##
            ## update: actually, doing setup with delegate_facts has 
            ##   one advantadge, it makes ansible_facts (container-context) 
            ##   principally avaible per hostvars[ansible_host] (as said 
            ##   before, ansible_facts var seems to say always at docker 
            ##   host context), if we do a 2nd setup without delegating 
            ##   facts afterwards, there is also no harm doing this first
            ##
          - setup:
            delegate_facts: True

          - setup:

          ##   ## TODO: is it possible to update ansible_facts explicitly with set_fact, is this necessary??
          ## - set_fact:
          ##     ansible_facts: "{{ hostvars[ansible_host].ansible_facts }}"


## handle docker copy
      - include_role:
          name: smabot.containers.copy_to_image
        vars:
          copy_to_image_args:
            copy_cfg: "{{ _cur_dockimg.docker_copy | default({}, True) }}"
            source_root: "{{ _cur_dockimg.role_dir }}"
            image_name: "{{ _cur_dockimg.shortname }}"
            image_owner: "{{ _cur_dockimg.owner }}"


## do steps prepackage
      - name: handle custom pre package install steps
        include_tasks: "{{ _cur_dockimg.steps.pre_packages }}"
        when: _cur_dockimg.get('steps', {}).get('pre_packages', None) is truthy


## do standard package install
      - name: standard distro package installs  ==>>  {{ _cur_dockimg.fullname }}
        include_tasks: package_install/main.yml


# handle user accounts
      - name: handle user '{{ _iter_img_users.key }}'  ==>>  {{ _dbimg_iter.value.fullname }}
        ansible.builtin.user: "{{ _iter_img_users.value.config }}"
        loop: "{{ _cur_dockimg.users.users | default({}, True) | dict2items() }}"
        loop_control:
          loop_var: _iter_img_users


#
# do java proxy handling
#
# note: we do this after standard package install step, as it is 
#   absolutely possible, that java is not pre inherited from 
#   parent, but is installed during this building operation, so 
#   we prefer it atm to be handled after package install
#
#   -> the big caveat of this is obviously if java is already 
#     installed before hand somehow and proxying for it is 
#     necessary, we cannot use it before we come to this 
#     point (e.g. for custom pre install steps)
#

        # is used for collecting java installation facts and maybe more
      - include_role: 
          name: smabot.base.extended_facts


      - block:

          - name: add java proxy envvars when appropriate
            set_fact:
              _cur_image_env: >-
                 {{ _cur_image_env | smabot.containers.append_contenv(
                      new_vars=(_cur_dockimg.proxy.eco_systems.java.envvars
                        | default(None)
                      ), strategy='combine'
                    )
                 }}

            ##
            ## do this either when config explicitly requested it, or 
            ## when auto dection is on and a java installation was 
            ## found in container system (which is expected to produce 
            ## some extended facts related to java)
            ##
            when: >-
              not _cur_dockimg.proxy.eco_systems.java.auto_detect
              or (_cur_dockimg.proxy.eco_systems.java.auto_detect
                  and ansible_facts.java is defined)


          - smabot.base.warn:
              msg: >-
                Configuration explicitly requested java proxy handling 
                but no java installation on container system could be found.

            when: >-
              not _cur_dockimg.proxy.eco_systems.java.auto_detect
              and ansible_facts.java is undefined

        when: _cur_dockimg.proxy.eco_systems.java.activate is truthy


## handle certificates
      - block:

          - name: handle extra ssl certificates
            include_role:
              name: smabot.base.handle_system_certs
            vars:
              handle_system_certs_args: >-
                {{ _cur_dockimg.ssl_certs | default({}, True) }}

            ##
            ## note: some ssl systems needs specific env vars set, 
            ##   and it is totally possible we want to use them 
            ##   for the rest of docker building
            ##
          - name: add certificate related envvars
            set_fact:
              _cur_image_env: >-
                 {{ _cur_image_env | smabot.containers.append_contenv(
                      new_vars=(handle_system_certs_result.envvars
                        | default(None)
                      )
                    )
                 }}
            when: handle_system_certs_result.envvars is truthy

        when: _cur_dockimg.get('ssl-certs', {}).get('disable', False) is falsy


## handle special package managers

      - name: pip package installs  ==>>  {{ _cur_dockimg.fullname }}
        ansible.builtin.pip: "{{ _iter_packinst }}" 
        loop: >-
          {{ _cur_dockimg.packages.pip 
           | smabot.containers.to_psets(auto_version=_autovcfg_iter) }}
        loop_control:
          loop_var: _iter_packinst


      - name: handle optional pip requirements files  ==>>  {{ _cur_dockimg.fullname }}
        include_tasks: pip_install/requirements.yml
        when: _cur_dockimg.packages.pip.requirements.sources


      - name: npm package installs  ==>>  {{ _cur_dockimg.fullname }}
        community.general.npm: "{{ _iter_packinst }}"
        loop: >-
          {{ _cur_dockimg.packages.npm
           | smabot.containers.to_psets(
                auto_version=_autovcfg_iter, grouped=False
             ) }}
        loop_control:
          loop_var: _iter_packinst

## do steps postpackage
      - name: handle custom post package install steps
        include_tasks: "{{ _cur_dockimg.steps.post_packages }}"
        when: _cur_dockimg.get('steps', {}).get('post_packages', None) is truthy

## do dynamic env


      - name: set container $USER envvar to configured docker_user  ==>>  {{ _dbimg_iter.value.fullname }}
        set_fact:
          _cur_image_env: >-
             {{ _cur_image_env | smabot.containers.append_contenv(
                  new_vars={'USER': _cur_dockimg.docker_user}
                )
             }}
        when: _cur_dockimg.docker_user


      ##
      ## note: as always atm direct uppdating per ansfact return is broken, 
      ##   so we use here also a workaround role for now
      ##
          ## - name: determine final environment (vars) for image  ==>>  {{ _dbimg_iter.value.fullname }}
          ##   smabot.containers.compute_container_env:
          ##     config_ansvar: '_cur_dockimg'

      - include_role:
          name: smabot.containers.compute_container_env
        vars:
          compute_contenv_args:
            task_name: determine final environment (vars) for image  ==>>  {{ _dbimg_iter.value.fullname }}
            config_ansvar: _cur_dockimg
            extra_envs:
              - "{{ _cur_image_env.vars }}"
              - "{{ _cur_image_deco | smabot.containers.deco_to_env }}"

      - debug:
          var: _cur_dockimg

## do dynamic labels

      - set_fact:
          _cur_image_labels: >-
            {{ _cur_image_labels 
             | combine((
                  _cur_image_deco | smabot.containers.deco_to_labels
               ))
            }}

## do final cleanup
      - include_tasks: final_cleanup/main.yml

## do final meta data collection
      - set_fact:
          _dbuild_meta: >-
            {{ _dbuild_meta | smabot.containers.combine_buildmeta(
                  metacfg=docker_build.meta, imgcfg=_cur_dockimg,
                  auto_versioning=_autovcfg_iter, ansible_facts=ansible_facts
               )
            }}
        when: docker_build.meta.create


    ##
    ## switch ansible context into the docker builder container 
    ## by using the delegate mechanism (as using "hosts:" 
    ## only works for top level playbooks)
    ##
    delegate_to: "{{ _bcon_name }}"

    ##
    ## make at least part of final image environment also avaible 
    ## during build phase, this is important for stuff like proxies
    ##
    ## note: environment seems to use actually a direct reference 
    ##   of the passed dict (not a copy of it), which means if we 
    ##   update this dict later during build these envvars are 
    ##   immediately avaible for following module calls, which 
    ##   than means we dont need extra nested blocks every time 
    ##   we update environment variables
    ##
    environment: >-
      {{ _cur_image_env.vars }}


##
## finally for committing and pushing we switch back to docker host
##
  - name: reset facts to docker host machine
    setup:


  - name: save build container to image  ==>>  {{ _dbimg_iter.value.fullname }}
    smabot.containers.docker_commit:
      container: "{{ _bcon_name }}" ## id or tag, mandatory
      image_name: "{{ _build_img_tmpname }}" ## image name, mandatory
      ##image_tag: ## optional, defaults to docker default (latest)

      ## if image already exists, it will not be overwritten unless 
      ## force is set, existing here means simply something with given 
      ## image name + tag exist already on docker node or is pullable
      force: True

      authors: "{{ _cur_dockimg.authors | default(omit, true) }}"

      ## TODO: complete keywords
      docker_keywords:
        ## 1:1 analogous to dockerfile statements with the same name, all optional
        CMD: "{{ _cur_dockimg.docker_cmd }}"
        ENTRYPOINT: "{{ _cur_dockimg.entrypoint }}"
        ENV: "{{ _cur_dockimg.environment.static | default(omit, True) }}"
        EXPOSE: "{{ _cur_dockimg.expose | default(omit, True) }}"
        LABEL: "{{ _cur_image_labels }}"
        USER: "{{ _cur_dockimg.docker_user }}"
        WORKDIR: "{{ _cur_dockimg.workdir | default(omit, True) }}"


  - name: remove build container for  ==>>  {{ _dbimg_iter.value.fullname }}
    docker_container:
      name: "{{ _bcon_name }}"
      state: absent
    when: not (docker_build_keep_buildcon | default(False))


  - set_fact:
      _build_tags: "{{ _cur_dockimg.tags }}"

  - set_fact:
      _build_tags: "{{ [_autovcfg_iter.idtag] + _build_tags }}"
    when: _autovcfg_iter.idtag | default(False, True)

  - name: >-
      no explicit tags for this build found, so build default 
      tag latest  ==>>  {{ _dbimg_iter.value.fullname }}
    set_fact:
      _build_tags: ['latest']
    when: not _build_tags


  - include_tasks: postbuild_tasks.yml
    loop: "{{ _build_tags }}"
    loop_control:
      loop_var: _btag_iter


  - set_fact:
      _cur_image_meta: >-
        {{ _cur_image_meta | combine({'builds': [_dbuild_meta]},
            recursive=True, list_merge='append')
        }}
    when: docker_build.meta.create


##   - include_role: 
##       name: hashicorp_vault_sma_login
## 
##     ## TODO: use a lookup here instead
##   - block:
## 
##       - hashivault_read:
##           mount_point: secrets/kv2/sma/manual/default
##           secret: accounts/adservice/svc.integrity/pw
##           key: usr
##           version: 2
##         register: _dacc_usr
## 
##       - hashivault_read:
##           mount_point: secrets/kv2/sma/manual/default
##           secret: accounts/adservice/svc.integrity/pw
##           key: pw
##           version: 2
##         register: _dacc_pw
## 
##     environment:
##       VAULT_TOKEN: "{{ awxcred_hashivault_token }}"


##   - name: docker registry login
##     docker_login:
##       registry: "repositories.developer.sunnyportal.com:5000"
##       username: "{{ _dacc_usr.value }}"
##       password: "{{ _dacc_pw.value }}"
##       reauthorize: yes
## 
## ## TODO: for some reason this always fails with useless error message unknown:unknown
## ## TODO: maybe do this in the working jenkins context
## ##  - name: tag and push to registry  ==>>  {{ _dbimg_iter.value.fullname }}
## ##    docker_image:
## ##      name: "{{ _dbimg_iter.value.fullname }}"
## ##      repository: "repositories.developer.sunnyportal.com:5000/{{ _dbimg_iter.value.fullname }}"
## ##      ##tag: 7
## ##      force_tag: yes # might be necessary to overwrite existing images
## ##      push: yes
## ##      source: local
## 
## 
##   - name: docker registry logout
##     docker_login:
##       state: absent

